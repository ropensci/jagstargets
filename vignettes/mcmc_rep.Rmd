---
title: "Scaling MCMC pipelines"
output: rmarkdown::html_vignette
bibliography: mcmc_rep.bib
vignette: >
  %\VignetteIndexEntry{Scaling MCMC pipelines}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
# With the root.dir option below,
# this vignette runs the R code in a temporary directory
# so new files are written to temporary storage
# and not the user's file space.
knitr::opts_knit$set(root.dir = fs::dir_create(tempfile()))
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
if (identical(Sys.getenv("NOT_CRAN", unset = "false"), "false")) {
  knitr::opts_chunk$set(eval = FALSE)
}
library(R2jags)
library(dplyr)
library(targets)
library(jagstargets)
```

It is sometimes desirable to run one or more Bayesian models repeatedly across multiple simulated datasets. Examples:

1. Validate the implementation of a Bayesian model using simulation.
2. Simulate a randomized controlled experiment to explore frequentist properties such as power and Type I error.

This vignette focuses on (1). The goal of this particular example to simulate multiple datasets from the model below, analyze each dataset, and assess how often the estimated posterior intervals cover the true parameters from the prior predictive simulations. The quantile method by @cook2006 generalizes this concept, and simulation-based calibration [@talts2020] generalizes further. The interval-based technique featured in this vignette is not as robust as SBC, but it may be more expedient for large models because it does not require visual inspection of multiple histograms.

```{r}
lines <- "model {
  for (i in 1:n) {
    y[i] ~ dnorm(alpha + x[i] * beta[i], 1)
    beta[i] ~ dnorm(0, 1)
  }
  alpha ~ dnorm(0, 1)
}"
writeLines(lines, "model.jags")
```

Next, we define a pipeline to simulate multiple datasets and fit each dataset with the model. In our data-generating function, we put the true parameter values of each simulation in a special `.join_data` list. `jagstargets` will automatically join the elements of `.join_data` to the correspondingly named variables in the summary output. This will make it super easy to check how often our posterior intervals capture the truth. As for scale, we declare 10 replications: 2 batches with 5 iterations per batch. (In practical situations, the total number of replications should be hundreds of times more.) 

```{r, echo = FALSE}
library(targets)
tar_script({
  library(jagstargets)
  options(crayon.enabled = FALSE)
  tar_option_set(memory = "transient", garbage_collection = TRUE)
  generate_data <- function (n = 10L) {
    alpha <- stats::rnorm(n = 1, mean = 0, sd = 1)
    beta <- stats::rnorm(n = n, mean = 0, sd = 1)
    x <- seq(from = -1, to = 1, length.out = n)
    y <- stats::rnorm(n, x * beta, 1)
    .join_data <- list(alpha = alpha, beta = beta)
    list(n = n, x = x, y = y, .join_data = .join_data)
  }
  list(
    tar_jags_rep_summary(
      model,
      "model.jags",
      data = generate_data(),
      parameters.to.save = c("alpha", "beta"),
      batches = 5, # Number of branch targets.
      reps = 2, # Number of model reps per branch target.
      log = R.utils::nullfile(),
      variables = c("alpha", "beta"),
      summaries = list(
        ~posterior::quantile2(.x, probs = c(0.025, 0.975))
      )
    )
  )
})
```

```{r, eval = FALSE}
# _targets.R
library(targets)
library(jagstargets)
options(crayon.enabled = FALSE)
tar_option_set(memory = "transient", garbage_collection = TRUE)

generate_data <- function (n = 10L) {
  alpha <- stats::rnorm(n = 1, mean = 0, sd = 1)
  beta <- stats::rnorm(n = n, mean = 0, sd = 1)
  x <- seq(from = -1, to = 1, length.out = n)
  y <- stats::rnorm(n, x * beta, 1)
  # Elements of .join_data get joined on to the .join_data column
  # in the summary output next to the model parameters
  # with the same names.
  .join_data <- list(alpha = alpha, beta = beta)
  list(n = n, x = x, y = y, .join_data = .join_data)
}

list(
  tar_jags_rep_summary(
    model,
    "model.jags",
    data = generate_data(),
    parameters.to.save = c("alpha", "beta"),
    batches = 5, # Number of branch targets.
    reps = 2, # Number of model reps per branch target.
    log = R.utils::nullfile(),
    variables = c("alpha", "beta"),
    summaries = list(
      ~posterior::quantile2(.x, probs = c(0.025, 0.975))
    )
  )
)
```

We now have a pipeline that runs the model 10 times: 5 batches (branch targets) with 2 replications per batch.

```{r}
tar_visnetwork()
```

Run the computation with `tar_make()`

```{r, output = FALSE, warning = FALSE}
tar_make()
```

The result is an aggregated data frame of summary statistics, where the `.rep` column distinguishes among individual replicates. We have the posterior intervals for `beta` in columns `q2.5` and `q97.5`. And thanks to the `.join_data` list we included in `generate_data()`, our output has a `.join_data` column with the true values of the parameters in our simulations.

```{r}
tar_load(model)
model
```

Now, let's assess how often the estimated 95% posterior intervals capture the true values of `beta`. If the model is implemented correctly, the coverage value below should be close to 95%. (Ordinarily, we would [increase the number of batches and reps per batch](https://books.ropensci.org/targets/dynamic.html#batching) and [run batches in parallel computing](https://books.ropensci.org/targets/hpc.html).)

```{r}
library(dplyr)
model %>%
  group_by(variable) %>%
  dplyr::summarize(coverage = mean(q2.5 < .join_data & .join_data < q97.5))
```

For maximum reproducibility, we should express the coverage assessment as a custom function and a target in the pipeline.

```{r, echo = FALSE}
library(targets)
tar_script({
  library(jagstargets)
  options(crayon.enabled = FALSE)
  tar_option_set(
    packages = "dplyr",
    memory = "transient",
    garbage_collection = TRUE
  )
  generate_data <- function (n = 10L) {
    alpha <- stats::rnorm(n = 1, mean = 0, sd = 1)
    beta <- stats::rnorm(n = n, mean = 0, sd = 1)
    x <- seq(from = -1, to = 1, length.out = n)
    y <- stats::rnorm(n, x * beta, 1)
    # Elements of .join_data get joined on to the .join_data column
    # in the summary output next to the model parameters
    # with the same names.
    .join_data <- list(alpha = alpha, beta = beta)
    list(n = n, x = x, y = y, .join_data = .join_data)
  }
  list(
    tar_jags_rep_summary(
      model,
      "model.jags",
      data = generate_data(),
      parameters.to.save = c("alpha", "beta"),
      batches = 5, # Number of branch targets.
      reps = 2, # Number of model reps per branch target.
      log = R.utils::nullfile(),
      variables = c("alpha", "beta"),
      summaries = list(
        ~posterior::quantile2(.x, probs = c(0.025, 0.975))
      )
    ),
    tar_target(
      coverage,
      model %>%
        group_by(variable) %>%
        summarize(
          coverage = mean(q2.5 < .join_data & .join_data < q97.5),
          .groups = "drop"
        )
    )
  )
})
```

```{r, eval = FALSE}
# _targets.R
library(targets)
library(jagstargets)

generate_data <- function (n = 10L) {
  alpha <- stats::rnorm(n = 1, mean = 0, sd = 1)
  beta <- stats::rnorm(n = n, mean = 0, sd = 1)
  x <- seq(from = -1, to = 1, length.out = n)
  y <- stats::rnorm(n, x * beta, 1)
  # Elements of .join_data get joined on to the .join_data column
  # in the summary output next to the model parameters
  # with the same names.
  .join_data <- list(alpha = alpha, beta = beta)
  list(n = n, x = x, y = y, .join_data = .join_data)
}

list(
  tar_jags_rep_summary(
    model,
    "model.jags",
    data = generate_data(),
    parameters.to.save = c("alpha", "beta"),
    batches = 5, # Number of branch targets.
    reps = 2, # Number of model reps per branch target.
    log = R.utils::nullfile(),
    variables = c("alpha", "beta"),
    summaries = list(
      ~posterior::quantile2(.x, probs = c(0.025, 0.975))
    )
  ),
  tar_target(
    coverage,
    model %>%
      group_by(variable) %>%
      summarize(
        coverage = mean(q2.5 < .join_data & .join_data < q97.5),
        .groups = "drop"
      )
  )
)
```

The new `coverage` target should the only outdated target, and it should be connected to the upstream `model` target.

```{r}
tar_visnetwork()
```

When we run the pipeline, only the coverage assessment should run. That way, we skip all the expensive computation of simulating datasets and running MCMC multiple times.

```{r, output = FALSE, warning = FALSE}
tar_make()
```

```{r}
tar_read(coverage)
```

## Multiple models

`tar_jags_rep_mcmc_summary()` and similar functions allow you to supply multiple jags models. If you do, each model will share the the same collection of datasets. Below, we add a new `model2.jags` file to the `jags_files` argument of `tar_jags_rep_mcmc_summary()`. In the coverage summary below, we group by `.name` to compute a coverage statistic for each model.


```{r, echo = FALSE}
library(targets)
tar_script({
  library(jagstargets)
  options(crayon.enabled = FALSE)
  tar_option_set(
    packages = "dplyr",
    memory = "transient",
    garbage_collection = TRUE
  )
  generate_data <- function (n = 10L) {
    alpha <- stats::rnorm(n = 1, mean = 0, sd = 1)
    beta <- stats::rnorm(n = n, mean = 0, sd = 1)
    x <- seq(from = -1, to = 1, length.out = n)
    y <- stats::rnorm(n, x * beta, 1)
    # Elements of .join_data get joined on to the .join_data column
    # in the summary output next to the model parameters
    # with the same names.
    .join_data <- list(alpha = alpha, beta = beta)
    list(n = n, x = x, y = y, .join_data = .join_data)
  }
  list(
    tar_jags_rep_summary(
      model,
      c("model.jags", "model2.jags"), # another model
      data = generate_data(),
      parameters.to.save = c("alpha", "beta"),
      batches = 5,
      reps = 2,
      log = R.utils::nullfile(),
      variables = c("alpha", "beta"),
      summaries = list(
        ~posterior::quantile2(.x, probs = c(0.025, 0.975))
      )
    ),
    tar_target(
      coverage,
      model %>%
        group_by(.name) %>%
        summarize(coverage = mean(q2.5 < .join_data & .join_data < q97.5))
    )
  )
})
```

```{r, eval = FALSE}
# _targets.R
library(targets)
library(jagstargets)

generate_data <- function (n = 10L) {
  alpha <- stats::rnorm(n = 1, mean = 0, sd = 1)
  beta <- stats::rnorm(n = n, mean = 0, sd = 1)
  x <- seq(from = -1, to = 1, length.out = n)
  y <- stats::rnorm(n, x * beta, 1)
  # Elements of .join_data get joined on to the .join_data column
  # in the summary output next to the model parameters
  # with the same names.
  .join_data <- list(alpha = alpha, beta = beta)
  list(n = n, x = x, y = y, .join_data = .join_data)
}

list(
  tar_jags_rep_summary(
    model,
    c("model.jags", "model2.jags"), # another model
    data = generate_data(),
    parameters.to.save = c("alpha", "beta"),
    batches = 5,
    reps = 2,
    log = R.utils::nullfile(),
    variables = c("alpha", "beta"),
    summaries = list(
      ~posterior::quantile2(.x, probs = c(0.025, 0.975))
    )
  ),
  tar_target(
    coverage,
    model %>%
      group_by(.name) %>%
      summarize(coverage = mean(q2.5 < .join_data & .join_data < q97.5))
  )
)
```

In the graph below, notice how targets `model_model1` and `model_model2` are both connected to `model_data` upstream. Downstream, `model` is equivalent to `dplyr::bind_rows(model_model1, model_model2)`, and it will have special columns `.name` and `.file` to distinguish among all the models.

```{r}
tar_visnetwork()
```

## References
